
@inproceedings{sun_short-term_2018,
	title = {Short-term Transit Decision Support System Using Multi-task Deep Neural Networks},
	booktitle = {The 4th IEEE International Conference on Smart Computing (SMARTCOMP 2018)},
	publisher = {IEEE},
	author = {Sun, Fangzhou and Dubey, Abhishek and Samal, Chinmaya and Baroud, Hiba and Kulkarni, Chetan},
	year = {2018}
}

@inproceedings{sun_distributed_2018,
	address = {San Luis Obispo},
	title = {Distributed and Stacked Neural Network for Anomaly Detection in Small Satellites},
	abstract = {The International Space Station (ISS) plans to launch 100+ small-sat missions for different science experiments in the next coming years. At present these missions are limited to couple of months but in the future these will last longer and it becomes crucial to monitor and predict future health of these systems as they age to prolong the usage time. This paper describes a hierarchical architecture which combines data-driven anomaly detection methods with a fine-grained model based diagnosis and prognostics architecture. At the core of the architecture is a distributed stack of deep neural network that detects and classifies the data traces from nearby satellites based on prior observations. Any identified anomaly is transmitted to the ground, which then uses model-based diagnosis and prognosis methods. In parallel, periodically the data traces from the satellites are transported to the ground and analyzed using model-based techniques. This data is then used to train the neural networks, which are run from ground systems and periodically updated. This collaborative architecture enables quick data-driven inference on the satellite and more intensive analysis on the ground where often time and power consumption are not key concerns. We demonstrate this architecture through an initial battery data set. In the future we propose to apply this framework to other electric and electronic components onboard the small satellites.},
	booktitle = {15th Annual Cubesat Developer Workshop},
	author = {Sun, Fangzhou and Dubey, Abhishek and Kulkarni, Chetan and Guarneros, A.},
	year = {2018}
}

@inproceedings{sun_dxnat_2017,
	title = {DxNAT- Deep neural networks for explaining non-recurring traffic congestion},
	doi = {10.1109/BigData.2017.8258162},
	booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
	author = {Sun, F. and Dubey, A. and White, J.},
	month = {dec},
	year = {2017},
	keywords = {anomaly detection, data augmentation method, Data models, deep learning, DxNAT, Games, Hidden Markov models, image data, Machine learning, multilayered deep neural network, neural nets, neural network, Neural networks, nonrecurring traffic congestion, pattern classification, public transportation, real-time data, real-time traffic speed, Roads, sensitivity analysis, Sensors, temporary disruptions, traffic congestion, traffic congestion indicator, traffic engineering computing},
	pages = {2141--2150}
}

@article{eisele_solidworx:_2018,
	title = {SolidWorx: A Resilient and Trustworthy Transactive Platform for Smart and Connected Communities},
	journal = {ArXiv e-prints},
	author = {Eisele, S. and Laszka, A. and Mavridou, A. and Dubey, A.},
	month = {apr},
	year = {2018},
	keywords = {and Cluster Computing, Computer Science - Distributed, Parallel}
}

@inproceedings{hasan_vulnerability_2018,
	title = {Vulnerability Analysis of Power Systems Based on Cyber-Attack and Defense Models},
	booktitle = {Innovative Smart Grid Technologies Conference (ISGT), 2018 IEEE Power \& Energy Society},
	publisher = {IEEE},
	author = {Hasan, Saqib and Ghafouri, Amin and Dubey, Abhishek and Karsai, Gabor and Koutsoukos, Xenofon},
	year = {2018}
}

@inproceedings{pettet_incident_2017,
	title = {Incident Analysis and Prediction Using Clustering And Bayesian Network},
	abstract = {Advances in data collection and storage infrastructure offer an unprecedented opportunity to integrate both data and emergency resources in a city into a dynamical learning system that can anticipate and rapidly respond to heterogeneous incidents. In this paper we describe integration methods for spatio-temporal incident forecasting using previously collected data provided to us by the Nashville Fire Department. The literature provides several techniques that focus on analyzing features and predicting accidents for specific situations (specific intersections in a city, or certain segments of a freeway, for example), but these models break down when applied to a large, general area consisting of several road and intersection types and several unknown factors. We use clustering analysis to categorize incidents to account for these unknown variables. The prediction methods we have developed lay the foundation for future work on a optimal emergency resource allocation and dispatch framework in the city of Nashville.},
	booktitle = {2017 IEEE International Conference on Smart City Innovations},
	publisher = {IEEE},
	author = {Pettet, Geoffrey and Nannapaneni, Saideep and Stadnick, Benjamin and Dubey, Abhishek and Biswas, Gautam},
	month = {aug},
	year = {2017},
	keywords = {Bayesian Inference, Incident Prediction, Survival Analysis, Unsupervised Clustering}
}

@inproceedings{eisele_adas_2016,
	address = {Detroit, Michigan, USA},
	title = {ADAS Virtual Prototyping with the OpenMETA Toolchain},
	abstract = {Complex systems, such as modern advanced driver assistance systems (ADAS), consist of many interacting components. The number of options promises considerable flexibility for configuring systems with many cost-performance-value tradeoffs; however the potential unique configurations are exponentially many prohibiting a build-test-fix approach. Instead, engineering analysis tools for rapid design-space navigation and analysis can be applied to find feasible options and evaluate their potential for correct system behavior and performance subject to functional requirements. The OpenMETA toolchain is a component-based, design space creation and analysis tool for rapidly defining and analyzing systems with large variability and cross-domain requirements. The tool supports the creation of compositional, multi-domain components, based on a user-defined ontology, which captures the behavior and structure of components and the allowable interfaces. Design spaces in OpenMETA allow product families to be defined in a single model, with component/subsystem alternatives and parametric variation. Using this system design space, OpenMETA then enables analysis of the system, via composition of the system and environment/scenario models into engineering tools, and executing simulations to compute metrics. System models can be created and executed in many abstractions based on the required accuracy, phenomena, and execution speed. This paper explores use cases from simulations with high fidelity components, to a gamified environment using Unity with a simple model of vehicle physics. This allows for user-in-the-loop analysis of controllers and components. This approach benefits ADAS by allowing for rapid prototyping across an array of candidate designs while evaluating the requirements of the vehicle at the appropriate fidelity level.},
	booktitle = {SAE 2016 World Congress \& Exhibition},
	publisher = {SAE International},
	author = {Eisele, Scott and Yamaura, Masahiro and Arechiga, Nikos and Shiraishi, Shinichi and Hite, Joseph and Scott, Jason and Neema, Sandeep and Bapty, Theodore},
	month = {apr},
	year = {2016}
}

@inproceedings{nannapaneni_performance_2017,
	title = {Performance evaluation of smart systems under uncertainty},
	abstract = {This paper develops a model-based framework for the quantification and propagation of multiple uncertainty sources affecting the performance of a smart system. A smart system, in general, performs sensing, control and actuation for proper functioning of a physical system (also referred to as a plant). With strong feedback coupling between the subsystems of a smart system, the uncertainty in the quantities of interest (QoI) amplifies over time. The coupling in a generic smart system occurs at two levels: (1) coupling between individual subsystems (plant, cyber, actuation, sensors), and (2) coupling between nodes in a distributed computational system. In this paper, a coupled smart system is decoupled and considered as a feed-forward system over time and modeled using a two-level Dynamic Bayesian Network (DBN), one at each level of coupling (between systems and between nodes). A DBN can aggregate uncertainty from multiple sources within a time step and across time steps. The DBN associated with a smart system can be learned using available system models, physics equations and data (both historic and operational). The proposed methodology is demonstrated for the design of a smart indoor heating system (identification of sensors and a wireless network) within cost constraints that enables room-by-room temperature control. We observe that sensor uncertainty has a higher impact on the performance of the heating system compared to the uncertainty in the wireless network.},
	booktitle = {2017 IEEE Smart World Congress},
	publisher = {IEEE},
	author = {Nannapaneni, Saideep and Dubey, Abhishek and Mahadevan, Sankaran},
	month = {aug},
	year = {2017},
	keywords = {Bayesian, Dynamic, Performance, Reliability, Smart System, Thermostat, Uncertainty}
}

@inproceedings{oruganti_delayradar-_2016,
	title = {DelayRadar- A multivariate predictive model for transit systems},
	doi = {10.1109/BigData.2016.7840797},
	abstract = {Effective public transit operations are one of the fundamental requirements for a modern community. Recently, a number of transit agencies have started integrating automated vehicle locators in their fleet, which provides a real-time estimate of the time of arrival. In this paper, we use the data collected over several months from one such transit system and show how this data can be potentially used to learn long term patterns of travel time. More specifically, we study the effect of weather and other factors such as traffic on the transit system delay. These models can later be used to understand the seasonal variations and to design adaptive and transient transit schedules. Towards this goal, we also propose an online architecture called DelayRadar. The novelty of DelayRadar lies in three aspects: (1) a data store that collects and integrates real-time and static data from multiple data sources, (2) a predictive statistical model that analyzes the data to make predictions on transit travel time, and (3) a decision making framework to develop an optimal transit schedule based on variable forecasts related to traffic, weather, and other impactful factors. This paper focuses on identifying the model with the best predictive accuracy to be used in DelayRadar. According to the preliminary study results, we are able to explain more than 70\% of the variance in the bus travel time and we can make future travel predictions with an out-of-sample error of 4.8 minutes with information on the bus schedule, traffic, and weather.},
	booktitle = {2016 IEEE International Conference on Big Data (Big Data)},
	author = {Oruganti, A. and Sun, F. and Baroud, H. and Dubey, A.},
	month = {dec},
	year = {2016},
	keywords = {Data models, traffic engineering computing, automated vehicle locators, Bus Delay, data storage, decision making, decision making framework, DelayRadar, Delays, Meteorology, multivariate predictive model, Prediction, Predictive models, public transit operations, public transport, Real-time systems, road traffic, Schedules, static data, statistical analysis, Traffic Flow, Transit, transit system delay, Urban areas, Weather},
	pages = {1799--1806}
}

@inproceedings{dubey_drems-os:_2017,
	title = {DREMS-OS: An Operating System for Managed Distributed Real-time Embedded Systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/paper_5.pdf},
	abstract = {Distributed real-time and embedded (DRE) systems executing mixed criticality task sets are increasingly being deployed in mobile and embedded cloud computing platforms, including space applications. These DRE systems must not only operate over a range of temporal and spatial scales, but also require stringent assurances for secure interactions between the system’s tasks without violating their individual timing constraints. To address these challenges, this paper describes a novel distributed operating system focusing on the scheduler design to support the mixed criticality task sets. Empirical results from experiments involving a case study of a cluster of satellites emulated in a laboratory testbed validate our claims.},
	booktitle = {Space Mission Challenges for Information Technology (SMC-IT)},
	author = {Dubey, Abhishek and Karsai, Gabor and Gokhale, Aniruddha and Emfinger, William and Kumar, Pranav},
	year = {2017}
}

@inproceedings{sun_unsupervised_2017,
	title = {Unsupervised Mechanisms for Optimizing On-Time Performance of Fixed Schedule Transit Vehicles},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/unsupervised-mechanisms-optimizing.pdf},
	abstract = {The on-time arrival performance of vehicles at stops is a critical metric for both riders and city planners to evaluate the reliability of a transit system. However, it is a non-trivial task for transit agencies to adjust the existing bus schedule to optimize the on-time performance for the future. For example, severe weather conditions and special events in the city could slow down traffic and cause bus delay. Furthermore, the delay of previous trips may affect the initial departure time of consecutive trips and generate accumulated delay. In this paper, we formulate the problem as a single-objective optimization task with constraints and propose a greedy algorithm and a genetic algorithm to generate bus schedules at timepoints that improves the bus ontime performance at timepoints which is indicated by whether the arrival delay is within the desired range. We use the Nashville bus system as a case study and simulate the optimization performance using historical data. The comparative analysis of the results identifies that delay patterns change over time and reveals the efficiency of the greedy and genetic algorithms.},
	booktitle = {3rd IEEE International Conference on Smart Computing},
	publisher = {IEEE},
	author = {Sun, Fangzhou and Samal, Chinamaya and White, Jules and Dubey, Abhishek},
	month = {may},
	year = {2017}
}

@inproceedings{sun_real-time_2016,
	title = {Real-Time and Predictive Analytics for Smart Public Transportation Decision Support System},
	doi = {10.1109/SMARTCOMP.2016.7501714},
	abstract = {Public bus transit plays an important role in city transportation infrastructure. However, public bus transit is often difficult to use because of lack of real- time information about bus locations and delay time, which in the presence of operational delays and service alerts makes it difficult for riders to predict when buses will arrive and plan trips. Precisely tracking vehicle and informing riders of estimated times of arrival is challenging due to a number of factors, such as traffic congestion, operational delays, varying times taken to load passengers at each stop. In this paper, we introduce a public transportation decision support system for both short-term as well as long-term prediction of arrival bus times. The system uses streaming real-time bus position data, which is updated once every minute, and historical arrival and departure data - available for select stops to predict bus arrival times. Our approach combines clustering analysis and Kalman filters with a shared route segment model in order to produce more accurate arrival time predictions. Experiments show that compared to the basic arrival time prediction model that is currently being used by the city, our system reduces arrival time prediction errors by 25\% on average when predicting the arrival delay an hour ahead and 47\% when predicting within a 15 minute future time window.},
	booktitle = {2016 IEEE International Conference on Smart Computing (SMARTCOMP)},
	author = {Sun, Fangzhou and Pan, Yao and White, Jules and Dubey, Abhishek},
	month = {may},
	year = {2016},
	keywords = {Data models, traffic congestion, Delays, Predictive models, public transport, Real-time systems, road traffic, Urban areas, arrival time prediction errors, bus delay time, bus locations, city transportation infrastructure, clustering analysis, decision support systems, Feeds, intelligent transportation systems, Kalman filters, long-term arrival bus times prediction, operational delays, pattern clustering, predictive analytics, public bus transit, real-time bus position data streaming, real-time information, real-time systems, road vehicles, service alerts, shared route segment model, short-term arrival bus times prediction, smart public transportation decision support system, times of arrival estimation, vehicle routing, vehicle tracking, Vehicles},
	pages = {1--8}
}

@inproceedings{balasubramanian_rapid_2014,
	title = {A Rapid Testing Framework for a Mobile Cloud},
	url = {http://dx.doi.org/10.1109/RSP.2014.6966903},
	doi = {10.1109/RSP.2014.6966903},
	abstract = {Mobile clouds such as network-connected vehicles and satellite clusters are an emerging class of systems that are extensions to traditional real-time embedded systems: they provide long-term mission platforms made up of dynamic clusters of heterogeneous hardware nodes communicating over ad hoc wireless networks. Besides the inherent complexities entailed by a distributed architecture, developing software and testing these systems is difficult due to a number of other reasons, including the mobile nature of such systems, which can require a model of the physical dynamics of the system for accurate simulation and testing. This paper describes a rapid development and testing framework for a distributed satellite system. Our solutions include a modeling language for configuring and specifying an application's interaction with the middleware layer, a physics simulator integrated with hardware in the loop to provide the system's physical dynamics and the integration of a network traffic tool to dynamically vary the network bandwidth based on the physical dynamics.},
	booktitle = {25nd IEEE International Symposium on Rapid System Prototyping, RSP 2014, New Delhi, India, October 16-17, 2014},
	author = {Balasubramanian, Daniel and Dubey, Abhishek and Otte, William R. and Emfinger, William and Kumar, Pranav Srinivas and Karsai, Gabor},
	year = {2014},
	pages = {128--134}
}

@inproceedings{balasubramanian_middleware_2010,
	address = {Washington, DC, USA},
	title = {Middleware for Resource-Aware Deployment and Configuration of Fault-Tolerant Real-time Systems},
	isbn = {978-0-7695-4001-6},
	doi = {http://dx.doi.org/10.1109/RTAS.2010.30},
	booktitle = {RTAS 2010: Proceedings of the 2010 16th IEEE Real-Time and Embedded Technology and Applications Symposium},
	publisher = {IEEE Computer Society},
	author = {Balasubramanian, Jaiganesh and Gokhale, Aniruddha and Dubey, Abhishek and Wolf, Friedhelm and Lu, Chenyang and Gill, Chris and Schmidt, Douglas},
	year = {2010},
	pages = {69--78}
}

@inproceedings{dabholkar_reliable_2012,
	title = {Reliable Distributed Real-Time and Embedded Systems through Safe Middleware Adaptation},
	doi = {10.1109/SRDS.2012.59},
	abstract = {Distributed real-time and embedded (DRE) systems are a class of real-time systems formed through a composition of predominantly legacy, closed and statically scheduled realtime subsystems, which comprise over-provisioned resources to deal with worst-case failure scenarios. The formation of the systems of systems leads to a new range of faults that manifest at different granularities for which no statically defined fault tolerance scheme applies. Thus, dynamic and adaptive fault tolerance mechanisms are needed which must execute within the available resources without compromising the safety and timeliness of existing real-time tasks in the individual subsystems. To address these requirements, this paper describes a middleware solution called Safe Middleware Adaptation for Real-Time Fault Tolerance (SafeMAT), which opportunistically leverages the available slack in the over-provisioned resources of individual subsystems. SafeMAT comprises three primary artifacts: (1) a flexible and configurable distributed, runtime resource monitoring framework that can pinpoint in real-time the available slack in the system that is used in making dynamic and adaptive fault tolerance decisions; (2) a safe and resourceaware dynamic failure adaptation algorithm that enables efficient recovery from different granularities of failures within the available slack in the execution schedule while ensuring real-time constraints are not violated and resources are not overloaded; and (3) a framework that empirically validates the correctness of the dynamic mechanisms and the safety of the DRE system. Experimental results evaluating SafeMAT on an avionics application indicates that SafeMAT incurs only 9-15 \% runtime failover and 2-6 \% processor utilization overheads at runtime thereby providing safe and predictable failure adaptability in real-time},
	booktitle = {Reliable Distributed Systems (SRDS), 2012 IEEE 31st Symposium on},
	author = {Dabholkar, A. and Dubey, A. and Gokhale, A. and Karsai, G. and Mahadevan, N.},
	month = {oct},
	year = {2012},
	keywords = {Real-time systems, Adaptation, adaptive fault tolerance decisions, adaptive fault tolerance mechanisms, avionics application, closed scheduled real-time subsystems, configurable distributed framework, distributed real-time and embedded, DRE systems, dynamic fault tolerance decisions, dynamic fault tolerance mechanisms, embedded systems, Fault tolerance, Fault Tolerance, Fault tolerant systems, flexible distributed framework, individual subsystems, middleware, Middleware, middleware solution, Monitoring, predictable failure adaptability, predominantly legacy, Profiling, real-time constraints, real-time fault tolerance, real-time tasks, Realtime, reliable distributed real-time systems, resource aware dynamic failure adaptation algorithm, Resource management, Runtime, runtime resource monitoring framework, safe middleware adaptation, SafeMAT, safety-critical software, software fault tolerance, Software Health Management, statically defined fault tolerance scheme, statically scheduled real-time subsystems, system-of-systems, worst-case failure scenarios},
	pages = {362--371}
}

@inproceedings{dubey_model-driven_2013,
	address = {Munich, Germany},
	title = {A Model-Driven Software Component Framework for Fractionated Spacecraft},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/f6mdk.pdf},
	abstract = {Fractionated spacecraft is a novel space architecture that uses a cluster of small spacecraft modules (with their own attitude control and propulsion systems) connected via wireless links to accomplish complex missions. Resources, such as sensors, persistent storage space, processing power, and downlink bandwidth can be shared among the members of the cluster thanks to the networking. Such spacecraft can serve as a cost effective, highly adaptable, and fault tolerant platform for running various distributed mission software applications that collect, process, and downlink data. Naturally, a key component in such a system is the software platform: the distributed operating system and software infrastructure that makes such applications possible. Existing operating systems are insufficient, and newer technologies like component frameworks do not address all the requirements of such flexible space architectures. The high degree of flexibility and the need for thorough planning and analysis of the resource management necessitates the use of advanced development techniques. This paper describes the core principles and design of a software component framework for fractionated spacecraft that is a special case of a distributed real-time embedded system. Additionally we describe how a model-driven development environment helps with the design and engineering of complex applications for this platform.},
	booktitle = {Proceedings of the 5th International Conference on Spacecraft Formation Flying Missions and Technologies (SFFMT)},
	publisher = {IEEE},
	author = {Dubey, Abhishek and Gokhale, Aniruddha and Karsai, Gabor and Otte, William and Willemsen, Johnny},
	month = {may},
	year = {2013}
}

@inproceedings{dubey_compensating_2009,
	address = {Los Alamitos, CA, USA},
	title = {Compensating for Timing Jitter in Computing Systems with General-Purpose Operating Systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Isorc_0.pdf},
	doi = {http://doi.ieeecomputersociety.org/10.1109/ISORC.2009.28},
	abstract = {Fault-tolerant frameworks for large scale computing clusters require sensor programs, which are executed periodically to facilitate performance and fault management. By construction, these clusters use general purpose operating systems such as Linux that are built for best average case performance and do not provide deterministic scheduling guarantees. Consequently, periodic applications show jitter in execution times relative to the expected execution time. Obtaining a deterministic schedule for periodic tasks in general purpose operating systems is difficult without using kernel-level modifications such as RTAI and RTLinux. However, due to performance and administrative issues kernel modification cannot be used in all scenarios. In this paper, we address the problem of jitter compensation for periodic tasks that cannot rely on modifying the operating system kernel. Towards that, (a) we present motivating examples; (b) we present a feedback controller based approach that runs in the user space and actively compensates periodic schedule based on past jitter; This approach is platform-agnostic i.e. it can be used in different operating systems without modification; and (c) we show through analysis and experiments that this approach is platform-agnostic i.e. it can be used in different operating systems without modification and also that it maintains a stable system with bounded total jitter.},
	booktitle = {IEEE International Symposium on Object-Oriented Real-Time Distributed Computing},
	publisher = {IEEE Computer Society},
	author = {Dubey, Abhishek and Karsai, Gabor and Abdelwahed, Sherif},
	year = {2009},
	pages = {55--62}
}

@inproceedings{dubey_real-time_2010,
	address = {Los Alamitos, CA, USA},
	title = {A Real-Time Component Framework: Experience with CCM and ARINC-653},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Paper_2.pdf},
	doi = {http://doi.ieeecomputersociety.org/10.1109/ISORC.2010.39},
	abstract = {The complexity of software in systems like aerospace vehicles has reached the point where new techniques are needed to ensure system dependability while improving the productivity of developers. One possible approach is to use precisely defined software execution platforms that (1) enable the system to be composed from separate components, (2) restrict component interactions and prevent fault propagation, and (3) whose compositional properties are well-known.In this paper we describe the initial steps towards building a platform that combines component-based software construction with hard real-time operating system services. Specifically, the paper discusses how the CORBA Component Model (CCM) could be combined with the ARINC-653 platform services and the lessons learned from this experiment. The results point towards both extending the CCM as well as revising the ARINC-653.},
	booktitle = {IEEE International Symposium on Object-Oriented Real-Time Distributed Computing},
	publisher = {IEEE Computer Society},
	author = {Dubey, Abhishek and Karsai, Gabor and Kereskenyi, Robert and Mahadevan, Nagabhushan},
	year = {2010},
	pages = {143--150}
}

@inproceedings{dubey_deliberative_2012,
	title = {A Deliberative Reasoner for Model-Based Software Health Management},
	url = {http://www.thinkmind.org/download.php?articleid=icas_2012_4_30_20079},
	abstract = {While traditional design-time and off-line approaches to testing and verification contribute significantly to improving and ensuring high dependability of software, they may not cover all possible fault scenarios that a system could encounter at runtime. Thus, runtime ‘health management’ of complex embedded software systems is needed to improve their dependability. Our approach to Software Health Management uses concepts from the field of ‘Systems Health Management’: detection, diagnosis and mitigation. In earlier work we had shown how to use a reactive mitigation strategy specified using a timed state machine model for system health manager. This paper describes the algorithm and key concepts for an alternative approach to system mitigation using a deliberative strategy, which relies on a function-allocation model to identify alternative component-assembly configurations that can restore the functions needed for the goals of the system.},
	booktitle = {The Eighth International Conference on Autonomic and Autonomous Systems},
	author = {Dubey, Abhishek and Mahadevan, Nagabhushan and Karsai, Gabor},
	year = {2012},
	pages = {86--92},
	annote = {Best Paper Award}
}

@inproceedings{dubey_scientific_2008,
	address = {Washington, DC, USA},
	title = {Scientific Computing Autonomic Reliability Framework},
	isbn = {978-0-7695-3535-7},
	doi = {http://dx.doi.org/10.1109/eScience.2008.113},
	abstract = {Large scientific computing clusters require a distributed dependability subsystem that can provide fault isolation and recovery and is capable of learning and predicting failures, to improve the reliability of scientific workflows. In this paper, we outline the key ideas in the design of a Scientific Computing Autonomic Reliability Framework (SCARF) for large computing clusters used in the Lattice Quantum Chromo Dynamics project at Fermi Lab.},
	booktitle = {ESCIENCE 2008: Proceedings of the 2008 Fourth IEEE International Conference on eScience},
	publisher = {IEEE Computer Society},
	author = {Dubey, Abhishek and Neema, Sandeep and Kowalkowski, Jim and Singh, Amitoj},
	year = {2008},
	pages = {352--353}
}

@inproceedings{dubey_information_2014,
	title = {An Information Architecture Platform for Mobile, Secure, and Resilient Distributed Systems},
	url = {http://cps-vo.org/file/12236/download/42058},
	booktitle = {High Confidence Software and Systems Conference},
	author = {Dubey, Abhishek and Otte, William and Karsai, Gabor},
	year = {2014}
}

@inproceedings{jain_improved_2015,
	title = {An Improved Distance Relay model with Directional element, and Memory Polarization for TCD based Fault Propagation Studies},
	abstract = {Modern Power Systems have evolved into a very complex network of multiple sources, lines, breakers, loads and others. The performance of these interdependent components decide the reliability of the power systems. A tool called “Reasoner” is being developed to deduce fault propagations using a Temporal Causal Diagram (TCD) approach. It translates the physical system as a Cause-effect model. This work discusses the development of an advanced distance relay model, which monitors the system, and challenges the operation of reasoner for refinement. Process of generation of a Fault and Discrepancy Mapping file from the test system is presented. This file is used by the reasoner to scrutinize relays’ responses for active system faults, and hypothesize potential mis-operations (or cyber faults) with a confidence metric. Analyzer (relay model) is integrated to OpenDSS for fault analysis. The understanding of the system interdependency (fault propagation behavior) using reasoner can make the grid more robust against cascaded failures.},
	booktitle = {North American Power Symposium (NAPS)},
	author = {Jain, Rishabh and Lukic, Srdjan and Chokra, Ajay and Mahadevan, Nag and Dubey, Abhishek and Karsai, Gabor},
	month = {oct},
	year = {2015},
	pages = {1--6}
}

@inproceedings{karsai_distributed_2014,
	title = {Distributed and Managed: Research Challenges and Opportunities of the Next Generation Cyber-Physical Systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/drems-isorc.pdf},
	doi = {10.1109/ISORC.2014.36},
	abstract = {Fractionated spacecraft - a cluster of simple satellites that are wirelessly connected, perform high-resolution sensing functions by running distributed sensor fusion applications. Coordinated swarms of networked Unmanned Aerial Vehicles carry out data collection damage assessment flights over large geographical areas affected by weather events. Fleets of Unmanned Underwater Vehicles collect climate change data from oceans with the help of sensor fusion and motion control applications. Smart data acquisition and control devices implement distributed sensing and control functions for the Smart Electric Grid. Such ‘cyber-physical cloud computing platforms’ present novel challenges because the system is built from mobile embedded devices, is inherently distributed and typically has highly fluctuating connectivity among the modules. Architecting software for these systems raises many challenges not present in traditional cloud computing. Effective management of constrained resources and application isolation without adversely affecting performance are necessary. Autonomous fault management and real-time performance requirements must be met in a verifiable manner. It is also both critical and challenging to support multiple end-users whose diverse software applications have changing demands for computational and communication resources, while operating on different levels and in separate domains of security. The solution presented in this paper is based on a layered architecture consisting of a novel operating system, a middleware layer, and component-structured applications. The component model facilitates the creation of software applications from modular and reusable components that are deployed in the distributed system and interact only through well-defined mechanisms. The complexity of creating applications and performing system integration is mitigated through the use of a domain-specific model-driven development process that relies on a domain-specific modeling language and its accompanying graphical modeling tools, software generators for synthesizing infrastructure code, and the extensive use of model-based analysis for verification and validation.},
	booktitle = {17th IEEE Symposium on Object/Component/Service-oriented Real-time Distributed Computing},
	author = {Karsai, Gabor and Balasubramanian, Daniel and Dubey, Abhishek and Otte, William R},
	month = {jun},
	year = {2014},
	keywords = {f6mdk},
	pages = {1--8}
}

@inproceedings{koo_reachlab:_2006,
	title = {ReachLab: Computation Platform for the Analysis of Hybrid Automata},
	booktitle = {9th International Workshop on Hybrid Systems: Computation and Control (HSCC 2006)},
	author = {Koo, Takkuen John and Wu, Xianbin and Su, Hang and Chen, Jie and Dubey, Abhishek},
	year = {2006}
}

@inproceedings{mahadevan_architecting_2012,
	title = {Architecting Health Management into Software Component Assemblies: Lessons Learned from the ARINC-653 Component Model},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Paper_9.pdf},
	doi = {10.1109/ISORC.2012.19},
	abstract = {Complex real-time software systems require an active fault management capability. While testing, verification and validation schemes and their constant evolution help improve the dependability of these systems, an active fault management strategy is essential to potentially mitigate the unacceptable behaviors at run-time. In our work we have applied the experience gained from the field of Systems Health Management towards component-based software systems. The software components interact via well-defined concurrency patterns and are executed on a real-time component framework built upon ARINC-653 platform services. In this paper, we present the lessons learned in architecting and applying a two-level health management strategy to assemblies of software components.},
	booktitle = {Object/Component/Service-Oriented Real-Time Distributed Computing (ISORC), 2012 IEEE 15th International Symposium on},
	author = {Mahadevan, Nag and Dubey, Abhishek and Karsai, Gabor},
	month = {apr},
	year = {2012},
	keywords = {real-time systems, Runtime, software fault tolerance, active fault management capability, ARINC-653 component model, ARINC-653 platform service, Assembly, complex real-time software system, component-based software system, concurrency control, concurrency pattern, constant evolution, Engines, Global Positioning System, object-oriented programming, program assemblers, program testing, program verification, Real time systems, real-time component framework, Software, software architecture, software component assemblies, systems health management, testing scheme, Timing, two-level health management strategy, validation scheme, verification scheme},
	pages = {79--86}
}

@inproceedings{mahadevan_application_2011,
	address = {Waikiki, Honolulu, HI, USA},
	series = {SEAMS 2011},
	title = {Application of Software Health Management Techniques},
	isbn = {978-1-4503-0575-4},
	url = {http://doi.acm.org/10.1145/1988008.1988010},
	doi = {10.1145/1988008.1988010},
	booktitle = {Proceedings of the 6th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
	publisher = {ACM},
	author = {Mahadevan, Nagabhushan and Dubey, Abhishek and Karsai, Gabor},
	year = {2011},
	keywords = {real-time systems, fault diagnosis and mitigation},
	pages = {1--10}
}

@article{biswas_application_2016,
	title = {An Application of Data Driven Anomaly Identification to Spacecraft Telemetry Data},
	abstract = {In this paper, we propose a mixed method for analyzing telemetry data from a robotic space mission. The idea is to first apply unsupervised learning methods to the telemetry data divided into temporal segments. The large clusters that ensue typically represent the nominal operations of the spacecraft and are not of interest from an anomaly detection viewpoint. However, the smaller clusters and outliers that result from this analysis may represent specialized modes of operation, e.g., conduct of a specialized experiment on board the spacecraft, or they may represent true anomalous or unexpected behaviors. To differentiate between specialized modes and anomalies, we employ a supervised method of consulting human mission experts in the approach presented in this paper. Our longer term goal is to develop more automated methods for detecting anomalies in time series data, and once anomalies are identified, use feature selection methods to build online detectors that can be used in future missions, thus contributing to making operations more effective and improving overall safety of the mission.},
	journal = {Annual Conference of the Prognostics and Health Management Society},
	author = {Biswas, Gautam and Khorasgani, Hamed and Stanje, Gerald and Dubey, Abhishek and Deb, Somnath and Ghoshal, Sudipto},
	year = {2016}
}

@article{mahadevan_temporal_2014,
	title = {Temporal causal diagrams for diagnosing failures in cyber-physical systems},
	url = {http://www.phmsociety.org/node/1439},
	abstract = {Resilient and reliable operation of cyber physical systems of societal importance such as Smart Electric Grids is one of the top national priorities. Due to their critical nature, these systems are equipped with fast-acting, local protection mechanisms. However, commonly misguided protection actions together with system dynamics can lead to un-intentional cascading effects. This paper describes the ongoing work using Temporal Causal Diagrams (TCD), a refinement of the Timed Failure Propagation Graphs (TFPG), to diagnose problems associated with the power transmission lines protected by a combination of relays and breakers. The TCD models represent the faults and their propagation as TFPG, the nominal and faulty behavior of components (including local, discrete controllers and protection devices) as Timed Discrete Event Systems (TDES), and capture the cumulative and cascading effects of these interactions. The TCD diagnosis engine includes an extended TFPG-like reasoner which in addition to observing the alarms and mode changes (as the TFPG), monitors the event traces (that correspond to the behavioral aspects of the model) to generate hypotheses that consistently explain all the observations. In this paper, we show the results of applying the TCD to a segment of a power transmission system that is protected by distance relays and breakers.},
	journal = {Annual Conference of the Prognostics and Health Management Society},
	author = {Mahadevan, Nagabhushan and Dubey, Abhishek and Karsai, Gabor and Srivastava, Anurag and Liu, Chen-Ching},
	year = {2014}
}

@inproceedings{martins_performance_2014,
	title = {Performance evaluation of an authentication mechanism in time-triggered networked control systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Performance%20Evaluation%20of%20an%20Authentication%20Mechanism%20in%20Time-Triggered%20Networked%20Control%20Systems.pdf},
	doi = {10.1109/ISRCS.2014.6900098},
	abstract = {An important challenge in networked control systems is to ensure the confidentiality and integrity of the message in order to secure the communication and prevent attackers or intruders from compromising the system. However, security mechanisms may jeopardize the temporal behavior of the network data communication because of the computation and communication overhead. In this paper, we study the effect of adding Hash Based Message Authentication (HMAC) to a time-triggered networked control system. Time Triggered Architectures (TTAs) provide a deterministic and predictable timing behavior that is used to ensure safety, reliability and fault tolerance properties. The paper analyzes the computation and communication overhead of adding HMAC and the impact on the performance of the time-triggered network. Experimental validation and performance evaluation results using a TTEthernet network are also presented.},
	booktitle = {Resilient Control Systems (ISRCS), 2014 7th International Symposium on},
	author = {Martins, G. and Bhattacharjee, A. and Dubey, A. and Koutsoukos, X.D.},
	month = {aug},
	year = {2014},
	keywords = {authentication mechanism, authorisation, communication overhead, computation overhead, computer network security, Cryptography, fault tolerance property, hash based message authentication, HMAC, local area networks, Message authentication, message confidentiality, message integrity, network data communication, networked control systems, Performance Evaluation, Receivers, reliability property, safety property, Secure Messages, security mechanisms, Switches, Synchronization, time triggered architectures, Time-Trigger Architectures, time-triggered networked control systems, timing behavior, TTEthernet, TTEthernet network},
	pages = {1--6}
}

@inproceedings{mehrotra_rfdmon:_2012,
	title = {RFDMon: A Real-time and Fault-tolerant Distributed System Monitoring Approach},
	url = {http://www.thinkmind.org/download.php?articleid=icas_2012_3_10_20052},
	abstract = {One of the main requirements for building an autonomic system is to have a robust monitoring framework. In this paper, a systematic distributed event based (DEB) system monitoring framework “RFDMon ” is presented for measuring system variables (CPU utilization, memory utilization, disk utilization, network utilization, etc.), system health (temperature and voltage of Motherboard and CPU) application performance variables (application response time, queue size, and throughput), and scientific application data structures (PBS information and MPI variables) accurately with minimum latency at a specified rate and with controllable resource utilization. This framework is designed to be tolerant to faults in monitoring framework, self-configuring (can start and stop monitoring the nodes and configure monitors for threshold values/changes for publishing the measurements), aware of execution of the framework on multiple nodes through HEARTBEAT messages, extensive (monitors multiple parameters through periodic and aperiodic sensors), resource constrainable (computational resources can be limited for monitors), and expandable for adding extra monitors on the fly. Since RFDMon uses a Data Distribution Services (DDS) middleware, it can be used for deploying in systems with heterogeneous nodes. Additionally, it provides a functionality to limit the maximum cap on resources consumed by monitoring processes such that it reduces the effect on the availability of resources for the applications.},
	booktitle = {Eighth International Conference on Autonomic and Autonomous Systems (ICAS)},
	author = {Mehrotra, Rajat and Dubey, Abhishek and Abdelwahed, Sherif and Krisa, Rowland},
	month = {mar},
	year = {2012},
	pages = {57--63}
}

@inproceedings{mehrotra_integrated_2010,
	address = {Los Alamitos, CA, USA},
	title = {Integrated Monitoring and Control for Performance Management of Distributed Enterprise Systems},
	doi = {http://doi.ieeecomputersociety.org/10.1109/MASCOTS.2010.57},
	abstract = {This paper describes an integrated monitoring and control framework for managing performance of distributed enterprise systems.},
	booktitle = {International Symposium on Modeling, Analysis, and Simulation of Computer Systems},
	publisher = {IEEE Computer Society},
	author = {Mehrotra, Rajat and Dubey, Abhishek and Abdelwahed, Sherif and Tantawi, Asser},
	year = {2010},
	pages = {424--426}
}

@article{nannapaneni_model-based_2014,
	title = {A Model-Based Approach for Reliability Assessment in Component-Based Systems},
	url = {http://www.phmsociety.org/node/1439},
	abstract = {This paper describes a formal framework for reliability assessment of component-based systems with respect to specific missions. A mission comprises of different timed mission stages, with each stage requiring a number of highlevel functions. The work presented here describes a modeling language to capture the functional decomposition and missions of a system. The components and their alternatives are mapped to basic functions which are used to implement the system-level functions. Our contribution is the extraction of mission-specific reliability block diagram from these high-level models of component assemblies. This is then used to compute the mission reliability using reliability information of components. This framework can be used for real-time monitoring of system performance where reliability of the mission is computed over time as the mission is in progress. Other quantities of interest such as mission feasibility, function availability can also be computed using this framework. Mission feasibility answers the question whether the mission can be accomplished given the current state of components in the system and function availability provides information if the function is available in the future given the current state of the system. The software used in this framework includes Generic Modeling Environment (GME) and Python. GME is used for modeling the system and Python for reliability computations. The proposed methodology is demonstrated using a radio-controlled (RC) car in carrying out a simple surveillance mission.},
	journal = {Annual Conference of the Prognostics and Health Management Society},
	author = {Nannapaneni, Saideep and Dubey, Abhishek and Abdelwahed, Sherif and Mahadevan, Sankaran and Neema, Sandeep},
	year = {2014}
}

@inproceedings{otte_f6com:_2013,
	title = {F6COM: A component model for resource-constrained and dynamic space-based computing environments},
	doi = {10.1109/ISORC.2013.6913199},
	abstract = {Component-based programming models are well-suited to the design of large-scale, distributed applications because of the ease with which distributed functionality can be developed, deployed, and validated using the models' compositional properties. Existing component models supported by standardized technologies, such as the OMG's CORBA Component Model (CCM), however, incur a number of limitations in the context of cyber physical systems (CPS) that operate in highly dynamic, resource-constrained, and uncertain environments, such as space environments, yet require multiple quality of service (QoS) assurances, such as timeliness, reliability, and security. To overcome these limitations, this paper presents the design of a novel component model called F6COM that is developed for applications operating in the context of a cluster of fractionated spacecraft. Although F6COM leverages the compositional capabilities and port abstractions of existing component models, it provides several new features. Specifically, F6COM abstracts the component operations as tasks, which are scheduled sequentially based on a specified scheduling policy. The infrastructure ensures that at any time at most one task of a component can be active - eliminating race conditions and deadlocks without requiring complicated and error-prone synchronization logic to be written by the component developer. These tasks can be initiated due to (a) interactions with other components, (b) expiration of timers, both sporadic and periodic, and (c) interactions with input/output devices. Interactions with other components are facilitated by ports. To ensure secure information flows, every port of an F6COM component is associated with a security label such that all interactions are executed within a security context. Thus, all component interactions can be subjected to Mandatory Access Control checks by a Trusted Computing Base that facilitates the interactions. Finally, F6COM provides capabilities to monitor - ask execution deadlines and to configure component-specific fault mitigation actions.},
	booktitle = {Object/Component/Service-Oriented Real-Time Distributed Computing (ISORC), 2013 IEEE 16th International Symposium on},
	author = {Otte, W.R. and Dubey, A. and Pradhan, S. and Patil, P. and Gokhale, A. and Karsai, G. and Willemsen, J.},
	month = {jun},
	year = {2013},
	keywords = {Real-time systems, object-oriented programming, Software, authorisation, aerospace computing, CCM, cluster and cloud, component models, component-based programming model, component-specific fault mitigation action, compositional capability, compositional property, Computational modeling, Connectors, CPS, cyber physical systems, distributed applications, distributed functionality, dynamic space-based computing environment, error-prone synchronization logic, F6COM component model, fault tolerant computing, fractionated spacecraft, mandatory access control checks, Message systems, mobility, OMG CORBA Component Model, port abstractions, Ports (Computers), QoS assurance, quality of service, resource-constrained computing environment, scheduling, scheduling policy, security context, space vehicles, Space vehicles, trusted computing, trusted computing base, wireless networking},
	pages = {1--8}
}

@inproceedings{roy_efficient_2011,
	title = {Efficient Autoscaling in the Cloud Using Predictive Models for Workload Forecasting},
	doi = {10.1109/CLOUD.2011.42},
	abstract = {Large-scale component-based enterprise applications that leverage Cloud resources expect Quality of Service(QoS) guarantees in accordance with service level agreements between the customer and service providers. In the context of Cloud computing, auto scaling mechanisms hold the promise of assuring QoS properties to the applications while simultaneously making efficient use of resources and keeping operational costs low for the service providers. Despite the perceived advantages of auto scaling, realizing the full potential of auto scaling is hard due to multiple challenges stemming from the need to precisely estimate resource usage in the face of significant variability in client workload patterns. This paper makes three contributions to overcome the general lack of effective techniques for workload forecasting and optimal resource allocation. First, it discusses the challenges involved in auto scaling in the cloud. Second, it develops a model-predictive algorithm for workload forecasting that is used for resource auto scaling. Finally, empirical results are provided that demonstrate that resources can be allocated and deal located by our algorithm in a way that satisfies both the application QoS while keeping operational costs low.},
	booktitle = {Cloud Computing (CLOUD), 2011 IEEE International Conference on},
	author = {Roy, Nilabja and Dubey, Abhishek and Gokhale, Aniruddha},
	month = {jul},
	year = {2011},
	keywords = {Resource management, object-oriented programming, quality of service, auto scaling mechanisms, autoscaling, client workload patterns, cloud computing, cloud resources, Cost function, model-predictive algorithm, optimal resource allocation, performance models, Prediction algorithms, predictive models, Quality of service, resource allocation, Throughput, Time factors, Virtual machining, workload forecasting},
	pages = {500--507}
}

@inproceedings{roy_capacity_2011,
	address = {Karlsruhe, Germany},
	series = {ICPE 2011},
	title = {A Capacity Planning Process for Performance Assurance of Component-based Distributed Systems},
	isbn = {978-1-4503-0519-8},
	url = {http://www.dre.vanderbilt.edu/~gokhale/WWW/papers/ICPE11_MAQPRO.pdf},
	doi = {http://doi.acm.org/10.1145/1958746.1958784},
	abstract = {For service providers of multi-tiered component-based applications, such as web portals, assuring high performance and availability to their customers without impacting revenue requires effective and careful capacity planning that aims at minimizing the number of resources, and utilizing them efficiently while simultaneously supporting a large customer base and meeting their service level agreements. This paper presents a novel, hybrid capacity planning process that results from a systematic blending of 1) analytical modeling, where traditional modeling techniques are enhanced to overcome their limitations in providing accurate performance estimates; 2) profile-based techniques, which determine performance profiles of individual software components for use in resource allocation and balancing resource usage; and 3) allocation heuristics that determine minimum number of resources to allocate software components. Our results illustrate that using our technique, performance (i.e., bounded response time) can be assured while reducing operating costs by using 25\% less resources and increasing revenues by handling 20\% more clients compared to traditional approaches.},
	booktitle = {Proceeding of the second joint WOSP/SIPEW international conference on Performance engineering},
	publisher = {ACM},
	author = {Roy, Nilabja and Dubey, Abhishek and Gokhale, Aniruddha and Dowdy, Larry},
	year = {2011},
	keywords = {multi-tier application, performance estimation, service deployment},
	pages = {259--270}
}

@inproceedings{shi_generic_2013,
	title = {Generic modeling and analysis framework for shipboard system design},
	doi = {10.1109/ESTS.2013.6523770},
	abstract = {This paper proposes a novel modeling and simulation environment for ship design based on the principles of Model Integrated Computing (MIC). The proposed approach facilitates the design and analysis of shipboard power systems and similar systems that integrate components from different fields of expertise. The conventional simulation platforms such as Matlab®, Simulink®, PSCAD® and VTB® require the designers to have explicit knowledge of the syntactic and semantic information of the desired domain within the tools. This constraint, however, severely slows down the design and analysis process, and causes cross-domain or cross-platform operations remain error prone and expensive. Our approach focuses on the development of a modeling environment that provides generic support for a variety of application across different domains by capturing modeling concepts, composition principles and operation constraints. For the preliminary demonstration of the modeling concept, in this paper we limit the scope of design to cross-platform implementations of the proposed environment by developing an application model of a simplified shipboard power system and using Matlab engine and VTB solver separately to evaluate the performance with different respects. In the case studies a fault scenario is pre-specified and tested on the system model. The corresponding time domain bus voltage magnitude and angle profiles are generated via invoking external solver, displayed to users and then saved for future analysis.},
	booktitle = {Electric Ship Technologies Symposium (ESTS), 2013 IEEE},
	author = {Shi, Jian and Amgai, R. and Abdelwahed, S. and Dubey, A. and Humphreys, J. and Alattar, M. and Jia, R.},
	month = {apr},
	year = {2013},
	keywords = {Computational modeling, Analytical models, angle profiles, Cross Platform Simulation, external solver, Generators, Generic Modeling Environment, Load modeling, marine power systems, Mathematical model, MATLAB, Matlab engine, MIC, model integrated computing, Model Integrated Computing, power engineering computing, Power system stability, PSCAD, semantic information, ship design, Shipboard Power System Design, shipboard power systems, Simulink, syntactic information, time domain bus voltage magnitude, time-domain analysis, VTB solver},
	pages = {420--428}
}

@inproceedings{karsai_distributed_2014-1,
	title = {Distributed and Managed: Research Challenges and Opportunities of the Next Generation Cyber-Physical Systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/drems-isorc.pdf},
	abstract = {Fractionated spacecraft - a cluster of simple satellites that are wirelessly connected, perform high-resolution sensing functions by running distributed sensor fusion applications. Coordinated swarms of networked Unmanned Aerial Vehicles carry out data collection damage assessment flights over large geographical areas affected by weather events. Fleets of Unmanned Underwater Vehicles collect climate change data from oceans with the help of sensor fusion and motion control applications. Smart data acquisition and control devices implement distributed sensing and control functions for the Smart Electric Grid. Such ‘cyber-physical cloud computing platforms’ present novel challenges because the system is built from mobile embedded devices, is inherently distributed and typically has highly fluctuating connectivity among the modules. Architecting software for these systems raises many challenges not present in traditional cloud computing. Effective management of constrained resources and application isolation without adversely affecting performance are necessary. Autonomous fault management and real-time performance requirements must be met in a verifiable manner. It is also both critical and challenging to support multiple end-users whose diverse software applications have changing demands for computational and communication resources, while operating on different levels and in separate domains of security. The solution presented in this paper is based on a layered architecture consisting of a novel operating system, a middleware layer, and component-structured applications. The component model facilitates the creation of software applications from modular and reusable components that are deployed in the distributed system and interact only through well-defined mechanisms. The complexity of creating applications and performing system integration is mitigated through the use of a domain-specific model-driven development process that relies on a domain-specific modeling language and its accompanying graphical modeling tools, software generators for synthesizing infrastructure code, and the extensive use of model-based analysis for verification and validation.},
	booktitle = {17th IEEE Symposium on Object/Component/Service-oriented Real-time Distributed Computing},
	author = {Karsai, Gabor and Balasubramanian, Daniel and Dubey, Abhishek and Otte, William R},
	month = {jun},
	year = {2014},
	keywords = {f6mdk}
}

@inproceedings{hasan_simulation_2017,
	title = {A Simulation Testbed for Cascade Analysis},
	booktitle = {Innovative Smart Grid Technologies Conference (ISGT), 2017 IEEE Power \& Energy Society},
	publisher = {IEEE},
	author = {Hasan, Saqib and Chhokra, Ajay and Dubey, Abhishek and Karsai, Nagabhushan Mahadevanand Gabor},
	year = {2017}
}

@inproceedings{neema_reusable_2016,
	address = {Portland, Oregon},
	title = {A Reusable and Extensible Web-Based Co-Simulation Platform for Transactive Energy Systems},
	abstract = {Rapid evolution of energy generation technology and increased used of distributed energy resources (DER) is continually pushing utilities to adapt and evolve business models to align with these changes. Today, more consumers are also producing energy using green generation technologies and energy pricing is becoming rather competitive and transactional, needing utilities to increase flexibility of grid operations and incorporate transactive energy systems (TES). However, a huge bottleneck is to ensure stable grid operations while gaining efficiency. A comprehensive platform is therefore needed for grid-scale multi-aspects integrated evaluations. For instance, cyber-attacks in a road traffic controller’s communication network can subtly divert electric vehicles in a particular area, causing surge in the grid loads due to increased EV charging and people activity, which can potentially disrupt, an otherwise robust, grid. To evaluate such a scenario, multiple special-purpose simulators (e.g., SUMO, OMNeT++, GridlabD, etc.) must be run in an integrated manner. To support this, we are developing a cloud-deployed web- and model-based simulation integration platform that enables integrated evaluations of transactive energy systems and is highly extensible and customizable for utility-specific custom simulation tools.},
	booktitle = {3rd International Transactive Energy Systems},
	publisher = {GridWise® Architecture Council},
	author = {Neema, Himanshu and Emfinger, William and Dubey, Abhishek},
	year = {2016}
}

@inproceedings{dubey_resilience_2017,
	address = {Valencia, Spain},
	title = {Resilience at the Edge in Cyber-Physical Systems},
	abstract = {As the number of low cost computing devices at the edge of communication network increase, there are greater opportunities to enable innovative capabilities, especially in cyber-physical systems. For example, micro-grid power systems can make use of computing capabilities at the edge of a Smart Grid to provide more robust and decentralized control. However, the downside to distributing intelligence to the edge away from the controlled environment of the data centers is the increased risk of failures. The paper introduces a framework for handling these challenges. The contribution of this framework is to support strategies to (a) tolerate the transient faults as they appear due to network fluctuations or node failures, and to (b) systematically reconfigure the application if the faults persist.},
	booktitle = {The 2nd International Conference on Fog and Mobile Edge Computing},
	publisher = {IEEE},
	author = {Dubey, Abhishek and Karsai, Gabor and Pradhan, Subhav},
	month = {may},
	year = {2017}
}

@inproceedings{khare_towards_2017,
	title = {Towards Low-Cost Indoor Localization using Edge Computing Resources},
	abstract = {Emerging smart services, such as indoor smart parking or patient monitoring and tracking in hospitals, incur a significant technical roadblock stemming primarily from a lack of cost-effective and easily deployable localization framework that impedes their widespread deployment.To address this concern, in this paper we present a low-cost, indoor localization and navigation system, which performs continuous and real-time processing of Bluetooth low Energy (BLE) and IEEE 802.15.4a compliant Ultra-wideband(UWB) sensor data to localize and navigate the concerned entity to its desired location. To keep deployment costs down, the indoor space in our solution is instrumented with (battery) as well as wired Edison devices, which provide both compute and BLE capabilities. Entities with managerial responsibilities in these scenarios can be equipped with both localization modalities: UWB tags and a BLE capable device (current generation smartphone or tablet), and are set up to maintain the BLE Received Signal Strength Intensity (RSSI) fingerprint map using the UWB positioning data as ground truth. The remaining entities rely exclusively on BLE RSSI fingerprinting-based localization using their smartphones.},
	booktitle = {20th IEEE International Symposium on Real-Time Computing (ISORC)},
	publisher = {IEEE},
	author = {Khare, Shweta and Sallai, Janos and Dubey, Abhishek and Gokhale, Aniruddha},
	month = {may},
	year = {2017}
}

@inproceedings{eisele_riaps-resilient_2017,
	address = {Toronto, Canada},
	title = {RIAPS-Resilient Information Architecture Platform for Decentralized Smart Systems},
	abstract = {The emerging Fog Computing paradigm provides an additional computational layer that enables new capabilities in real-time data-driven applications. This is especially interesting in the domain of Smart Grid as the boundaries between traditional generation, distribution, and consumer roles are blurring. This is a reflection of the ongoing trend of intelligence distribution in Smart Systems. In this paper, we briefly describe a component-based decentralized software platform called Resilient Information Architecture Platform for Smart Systems (RIAPS) which provides an infrastructure for such systems. We briefly describe some initial applications built using this platform. Then, we focus on the design and integration choices for a resilient Discovery Manager service that is a critical component of this infrastructure. The service allows applications to discover each other, work collaboratively, and ensure the stability of the Smart System.},
	booktitle = {20th IEEE International Symposium on Real-Time Computing (ISORC)},
	publisher = {IEEE},
	author = {Eisele, Scott and Madari, Istvan and Dubey, Abhishek and Karsai, Gabor},
	month = {may},
	year = {2017}
}

@inproceedings{emfinger_demo_2016,
	title = {Demo Abstract: RIAPS - A Resilient Information Architecture Platform for Edge Computing},
	booktitle = {2016 IEEE/ACM Symposium on Edge Computing (SEC)},
	publisher = {IEEE},
	author = {Emfinger, William and Dubey, Abhishek and Volgyesi, Peter and Sallai, Janos and Karsai, Gabor},
	year = {2016},
	pages = {119--120}
}

@inproceedings{eisele_wip_2017,
	title = {WiP Abstract: Transactive Energy Demo with RIAPS Platform},
	booktitle = {2017 International Conference on Cyber Physical Systems},
	author = {Eisele, Scott and Dubey, Abhishek and Karsai, Gabor and Lukic, Srdjan},
	year = {2017}
}

@inproceedings{pradhan_distributed_2016,
	title = {A Distributed and Resilient Platform for City-scale Smart Systems},
	booktitle = {2016 IEEE/ACM Symposium on Edge Computing (SEC)},
	publisher = {IEEE},
	author = {Pradhan, Subhav and Dubey, Abhishek and Khare, Shweta and Sun, Fangzhou and Sallai, Janos and Gokhale, Aniruddha and Schmidt, Douglas and Lehofer, Martin and Sturm, Monika},
	year = {2016},
	pages = {99--100}
}

@article{chhokra_system_2015,
	title = {From System Modeling to Formal Verification},
	issn = {2117-4628},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Session3_Paper3.pdf},
	abstract = {Due to increasing design complexity, modern systems are modeled at a high level of abstraction. SystemC is widely accepted as a system level language for modeling complex embedded systems. Verification of these SystemC designs nullifies the chances of error propagation down to the hardware. Due to lack of formal semantics of SystemC, the verification of such designs is done mostly in an unsystematic manner. This paper provides a new modeling environment that enables the designer to simulate and formally verify the designs by generating SystemC code. The generated SystemC code is automatically translated to timed automata for formal analysis.},
	journal = {The 2015 Electronic System Level Synthesis Conference},
	author = {Chhokra, Ajay and Abdelwahed, Sherif and Dubey, Abhishek and Neema, Sandeep and Karsai, Gabor},
	month = {jul},
	year = {2015}
}

@inproceedings{dubey_algorithms_2009,
	address = {Washington, DC, USA},
	title = {Algorithms for Synthesizing Safe Sets of Operation for Embedded Systems},
	isbn = {978-0-7695-3602-6},
	doi = {http://dx.doi.org/10.1109/ECBS.2009.43},
	abstract = {A large number of embedded computing systems are modeled as hybrid system with both discrete and continuous dynamics. In this paper, we present algorithms for analyzing nonlinear time-invariant continuous-time systems by employing reachability algorithms. We propose synthesis algorithms for finding sets of initial states for the continuous dynamical systems so that temporal properties, such as safety and liveness properties, are satisfied. The initial sets produced by the algorithms are related to some classical concepts for continuous dynamical systems, such as invariant sets and domains of attraction.},
	booktitle = {ECBS '09: Proceedings of the 2009 16th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems},
	publisher = {IEEE Computer Society},
	author = {Dubey, Abhishek},
	year = {2009},
	pages = {149--155}
}

@inproceedings{dubey_software_2012,
	title = {A software platform for fractionated spacecraft},
	doi = {10.1109/AERO.2012.6187334},
	abstract = {A fractionated spacecraft is a cluster of independent modules that interact wirelessly to maintain cluster flight and realize the functions usually performed by a monolithic satellite. This spacecraft architecture poses novel software challenges because the hardware platform is inherently distributed, with highly fluctuating connectivity among the modules. It is critical for mission success to support autonomous fault management and to satisfy real-time performance requirements. It is also both critical and challenging to support multiple organizations and users whose diverse software applications have changing demands for computational and communication resources, while operating on different levels and in separate domains of security. The solution proposed in this paper is based on a layered architecture consisting of a novel operating system, a middleware layer, and component-structured applications. The operating system provides primitives for concurrency, synchronization, and secure information flows; it also enforces application separation and resource management policies. The middleware provides higher-level services supporting request/response and publish/subscribe interactions for distributed software. The component model facilitates the creation of software applications from modular and reusable components that are deployed in the distributed system and interact only through well-defined mechanisms. Two cross-cutting aspects - multi-level security and multi-layered fault management - are addressed at all levels of the architecture. The complexity of creating applications and performing system integration is mitigated through the use of a domain-specific model-driven development process that relies on a dedicated modeling language and its accompanying graphical modeling tools, software generators for synthesizing infrastructure code, and the extensive use of model-based analysis for verification and validation.},
	booktitle = {Aerospace Conference, 2012 IEEE},
	author = {Dubey, A. and Emfinger, W. and Gokhale, A. and Karsai, G. and Otte, W.R. and Parsons, J. and Szabo, C. and Coglio, A. and Smith, E. and Bose, P.},
	month = {mar},
	year = {2012},
	keywords = {middleware, Middleware, object-oriented programming, aerospace computing, fractionated spacecraft, Space vehicles, application creation complexity, artificial satellites, autonomous fault management, cluster flight, communication resources, component-structured applications, computational complexity, computational resources, concurrency, Customer relationship management, distributed software, fault diagnosis, graphical modeling tools, infrastructure code synthesis, middleware layer, modeling language, monolithic satellite, multilayered fault management, multilevel security, multiple organizations, operating system, Operating systems, operating systems (computers), publish-subscribe interactions, request-response interactions, reusable components, secure information flows, Security, simulation languages, software generators, software platform, software reusability, spacecraft architecture, synchronization, Unified modeling language},
	pages = {1--20}
}

@inproceedings{dubey_model-based_2011,
	title = {Model-based software health management for real-time systems},
	doi = {10.1109/AERO.2011.5747559},
	abstract = {Complexity of software systems has reached the point where we need run-time mechanisms that can be used to provide fault management services. Testing and verification may not cover all possible scenarios that a system will encounter, hence a simpler, yet formally specified run-time monitoring, diagnosis, and fault mitigation architecture is needed to increase the software system's dependability. The approach described in this paper borrows concepts and principles from the field of “Systems Health Management” for complex systems and implements a two level health management strategy that can be applied through a model-based software development process. The Component-level Health Manager (CLHM) for software components provides a localized and limited functionality for managing the health of a component locally. It also reports to the higher-level System Health Manager (SHM) which manages the health of the overall system. SHM consists of a diagnosis engine that uses the timed fault propagation (TFPG) model based on the component assembly. It reasons about the anomalies reported by CLHM and hypothesizes about the possible fault sources. Thereafter, necessary system level mitigation action can be taken. System-level mitigation approaches are subject of on-going investigations and have not been included in this paper. We conclude the paper with case study and discussion.},
	booktitle = {Aerospace Conference, 2011 IEEE},
	author = {Dubey, Abhsihek and Karsai, Gabor and Mahadevan, Nagabhushan},
	month = {mar},
	year = {2011},
	keywords = {real-time systems, Monitoring, software fault tolerance, object-oriented programming, program testing, Software, software architecture, Analytical models, Biological system modeling, Biomedical monitoring, CLHM, component level health manager, fault mitigation architecture, formal verification, Heating, model based software health management, Publishing, real time system, SHM, software dependability, software reliability, software system complexity, software testing, software verification, system health manager, TFPG, timed fault propagation},
	pages = {1--18}
}

@inproceedings{dubey_verifying_2006,
	title = {Verifying autonomic fault mitigation strategies in large scale real-time systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Dubey_A_3_0_2006_Verifying_.pdf},
	abstract = {In large scale real-time systems many problems associated with self-management are exacerbated by the addition of time deadlines. In these systems any autonomic behavior must not only be functionally correct but they must also not violate properties of liveness, safety and bounded time responsiveness. In this paper we present and analyze a real-time Reflex Engine for providing fault mitigation capability to large scale real time systems. We also present a semantic domain for analyzing and verifying the properties of such systems along with the framework of real-time reflex engines.},
	booktitle = {3rd IEEE International Workshop on Engineering of Autonomic \& Autonomous Systems (EASe)},
	author = {Dubey, Abhishek and Nordstrom, Steve and Keskinpala, Turker and Neema, Sandeep and Bapty, Ted},
	year = {2006},
	pages = {129--140}
}

@inproceedings{dubey_towards_2008,
	title = {Towards A Model-Based Autonomic Reliability Framework for Computing Clusters},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Dubey_A_4_0_2008_Towards_A_.pdf},
	abstract = {One of the primary problems with computing clusters is to ensure that they maintain a reliable working state most of the time to justify economics of operation. In this paper, we introduce a model-based hierarchical reliability framework that enables periodic monitoring of vital health parameters across the cluster and provides for autonomic fault mitigation. We also discuss some of the challenges faced by autonomic reliability frameworks in cluster environments such as non-determinism in task scheduling in standard operating systems such as Linux and need for synchronized execution of monitoring sensors across the cluster. Additionally, we present a solution to these problems in the context of our framework, which utilizes a feedback controller based approach to compensate for the scheduling jitter in non real-time operating systems. Finally, we present experimental data that illustrates the effectiveness of our approach.},
	booktitle = {5th IEEE International Workshop on Engineering of Autonomic \& Autonomous Systems (EASe)},
	author = {Dubey, Abhishek and Nordstrom, Steve and Keskinpala, Turker and Neema, Sandeep and Bapty, Ted and Karsai, Gabor},
	year = {2008},
	pages = {75--85}
}

@inproceedings{dubey_using_2009,
	address = {Washington, DC, USA},
	title = {Using Runtime Verification to Design a Reliable Execution Framework for Scientific Workflows},
	isbn = {978-0-7695-3623-1},
	doi = {http://dx.doi.org/10.1109/EASe.2009.13},
	abstract = {In this paper, we describe the design of a scientific workflow execution framework that integrates runtime verification to monitor its execution and checking it against the formal specifications. For controlling workflow execution, this framework provides for data provenance, execution tracking and online monitoring of each work flow task, also referred to as participants. The sequence of participants is described in an abstract parameterized view, which is used to generate concrete data dependency based sequence of participants with defined arguments. As participants belonging to a workflow are mapped onto machines and executed, periodic and on-demand monitoring of vital health parameters on allocated nodes is enabled according to pre-specified invariant conditions with actions to be taken upon violation of invariants.},
	booktitle = {EASE '09: Proceedings of the 2009 Sixth IEEE Conference and Workshops on Engineering of Autonomic and Autonomous Systems},
	publisher = {IEEE Computer Society},
	author = {Dubey, Abhishek and Piccoli, Luciano and Kowalkowski, James B. and Simone, James N. and Sun, Xian-He and Karsai, Gabor and Neema, Sandeep},
	year = {2009},
	pages = {87--96}
}

@inproceedings{dubey_modeling_2009,
	address = {Los Alamitos, CA, USA},
	title = {Modeling and Analysis of Probabilistic Timed Systems},
	isbn = {978-0-7695-3602-6},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/PTAVerification_0.pdf},
	doi = {http://doi.ieeecomputersociety.org/10.1109/ECBS.2009.44},
	abstract = {Probabilistic models are useful for analyzing systems which operate under the presence of uncertainty. In this paper, we present a technique for verifying safety and liveness properties for probabilistic timed automata. The proposed technique is an extension of a technique used to verify stochastic hybrid automata using an approximation with Markov Decision Processes. A case study for CSMA/CD protocol has been used to show case the methodology used in our technique.},
	booktitle = {IEEE International Conference on the Engineering of Computer-Based Systems},
	publisher = {IEEE Computer Society},
	author = {Dubey, Abhishek and Riley, Derek and Abdelwahed, Sherif and Bapty, Ted},
	year = {2009},
	pages = {69--78}
}

@inproceedings{mahadevan_distributed_2010,
	title = {Distributed diagnosis of complex systems using timed failure propagation graph models},
	doi = {10.1109/AUTEST.2010.5613575},
	abstract = {Timed failure propagation graph (TFPG) is a directed graph model that represents temporal progression of failure effects in physical systems. In this paper, a distributed diagnosis approach for complex systems is introduced based on the TFPG model settings. In this approach, the system is partitioned into a set of local subsystems each represented by a subgraph of the global system TFPG model. Information flow between subsystems is achieved through special input and output nodes. A high level diagnoser integrates the diagnosis results of the local subsystems using an abstract high level model to obtain a globally consistent diagnosis of the system.},
	booktitle = {AUTOTESTCON, 2010 IEEE},
	author = {Mahadevan, N. and Abdelwahed, S. and Dubey, A. and Karsai, G.},
	month = {sep},
	year = {2010},
	keywords = {Monitoring, Software, Switches, Synchronization, Computational modeling, fault diagnosis, Cognition, complex system, directed graphs, distributed diagnosis, high level diagnoser, large-scale systems, Semantics, temporal progression, TFPG model, timed failure propagation graph model},
	pages = {1--6}
}

@inproceedings{mahadevan_using_2014,
	title = {Using temporal causal models to isolate failures in Power System protection devices},
	doi = {10.1109/AUTEST.2014.6935156},
	abstract = {Power transmission systems are instrumented with a network of fast-acting protection devices that detect anomalies and arrest the fault propagation, thereby isolating the faulty components to protect the remaining system. However, often a local protection action leads to cascading effects to other regions resulting in blackouts. Also, inherent faults in protection devices such as relays and breakers could lead to failed or misguided protection action. A fault model associated with such a system needs to capture the dynamic behavior of the system as well as protection scheme in both nominal and faulty modes of operation. With an effort to capture the temporal behavior and the fault propagation of the system and its autonomous protection mechanism, we propose a new modeling formalism - the Temporal Causal Diagram (TCD). In this paper, we will describe the TCD modeling formalism and apply it to create fault-models that capture the fault propagation and state evolution of the Power Systems and their autonomous protection units. Further, we showcase simulation models derived from the TCD models and use these to simulate single and multi-fault scenarios in power transmission systems.},
	booktitle = {AUTOTESTCON, 2014 IEEE},
	publisher = {IEEE},
	author = {Mahadevan, Nagabhushan and Dubey, Abhishek and Guo, Huangcheng and Karsai, Gabor},
	year = {2014},
	pages = {270--279}
}

@inproceedings{mehrotra_large_2011,
	title = {Large Scale Monitoring and Online Analysis in a Distributed Virtualized Environment},
	doi = {10.1109/EASe.2011.17},
	abstract = {Due to increase in number and complexity of the large scale systems, performance monitoring and multidimensional quality of service (QoS) management has become a difficult and error prone task for system administrators. Recently, the trend has been to use virtualization technology, which facilitates hosting of multiple distributed systems with minimum infrastructure cost via sharing of computational and memory resources among multiple instances, and allows dynamic creation of even bigger clusters. An effective monitoring technique should not only be fine grained with respect to the measured variables, but also should be able to provide a high level overview of the distributed systems to the administrator of all variables that can affect the QoS requirements. At the same time, the technique should not add performance burden to the system. Finally, it should be integrated with a control methodology that manages performance of the enterprise system. In this paper, a systematic distributed event based (DEB) performance monitoring approach is presented for distributed systems by measuring system variables (physical/virtual CPU utilization and memory utilization), application variables (application queue size, queue waiting time, and service time), and performance variables (response time, throughput, and power consumption) accurately with minimum latency at a specified rate. Furthermore, we have shown that proposed monitoring approach can be utilized to provide input to an application monitoring utility to understand the underlying performance model of the system for a successful on-line control of the distributed systems for achieving predefined QoS parameters.},
	booktitle = {Engineering of Autonomic and Autonomous Systems (EASe), 2011 8th IEEE International Conference and Workshops on},
	author = {Mehrotra, R. and Dubey, A. and Abdelwahed, S. and Monceaux, W.},
	month = {apr},
	year = {2011},
	keywords = {Sensors, Monitoring, Synchronization, quality of service, Quality of service, application queue size, DEB performance monitoring, distributed event based performance monitoring, distributed processing, distributed virtualized environment, large scale monitoring, memory utilization, monitoring, online analysis, performance analysis, physical CPU utilization, Power demand, QoS management, queue waiting time, service time, virtual CPU utilization, virtualizaton, Web servers},
	pages = {1--9}
}

@inproceedings{nordstrom_guided_2006,
	title = {A guided explorative approach for autonomic healing of model based systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Nordstrom_SG_7_0_2006_A_Guided_E.pdf},
	abstract = {Embedded computing is an area in which many of the Self-* properties of autonomic systems are desirable. Model based tools for designing embedded systems, while proven successful in many applications, are not yet applicable toward building autonomic or self-sustaining embedded systems. This paper reports on the progress made by our group in developing a model based toolset which specifically targets the creation of autonomic embedded systems.},
	booktitle = {Second IEEE conference on Space Mission Challenges for Information Technology (SMC-IT)},
	author = {Nordstrom, Steve and Bapty, Ted and Neema, Sandeep and Dubey, Abhishek and Keskinpala, Turker},
	month = {jul},
	year = {2006}
}

@inproceedings{nordstrom_ghost:_2006,
	title = {Ghost: Guided healing and optimization search technique for healing large-scale embedded systems},
	doi = {http://dx.doi.org/10.1109/EASE.2006.8},
	abstract = {Reflex and healing architectures have been shown to provide adequate user-defined initial failure mitigation behaviors in the presence of system faults. What is lacking, however, is a user-guided means of healing the system after the initial reflexes have been enacted. This process should be autonomic in the sense that new system configurations can be achieved by defining a priori only a small set of criteria to which the healed system should conform. What follows is an explanation of this technique for guided healing which allows system designers to direct the healing process from a higher level in such a way that the resulting system configurations satisfy their particular needs. A brief example outlining the application of this approach is given.},
	booktitle = {3rd IEEE International Workshop on Engineering of Autonomic \& Autonomous Systems (EASe)},
	author = {Nordstrom, Steve and Dubey, Abhishek and Keskinpala, Turker and Bapty, Ted and Neema, Sandeep},
	year = {2006},
	pages = {129--140}
}

@inproceedings{nordstrom_model_2007,
	title = {Model Predictive Analysis for Autonomic Workflow Management in Large-scale Scientific Computing Environments},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/WorkflowML.pdf},
	abstract = {In large scale scientific computing, proper planning and management of computational resources lead to higher system utilizations and increased scientific productivity. Scientists are increasingly leveraging the use of business process management techniques and workflow management tools to balance the needs of the scientific analyses with the availability of computational resources. However, the advancements in productivity from execution of workflows in a large scale computing environments are often thwarted by runtime resource failures. This paper presents our initial work toward autonomic model based fault analysis in workflow based environments.},
	booktitle = {4th IEEE International Workshop on Engineering of Autonomic \& Autonomous Systems (EASe)},
	author = {Nordstrom, Steve and Dubey, Abhishek and Keskinpala, Turker and Datta, Rahul and Neema, Sandeep and Bapty, Ted},
	year = {2007},
	pages = {37--42}
}

@inproceedings{otte_resilient_2014,
	title = {A Resilient and Secure Software Platform and Architecture for Distributed Spacecraft},
	abstract = {A distributed spacecraft is a cluster of independent satellite modules flying in formation that communicate via ad-hoc wireless networks. This system in space is a cloud platform that facilitates sharing sensors and other computing and communication resources across multiple applications, potentially developed and maintained by different organizations. Effectively, such architecture can realize the functions of monolithic satellites at a reduced cost and with improved adaptivity and robustness. Openness of these architectures pose special challenges because the distributed software platform has to support applications from different security domains and organizations, and where information flows have to be carefully managed and compartmentalized. If the platform is used as a robust shared resource its management, configuration, and resilience becomes a challenge in itself. We have designed and prototyped a distributed software platform for such architectures. The core element of the platform is a new operating system whose services were designed to restrict access to the network and the file system, and to enforce resource management constraints for all non-privileged processes Mixed-criticality applications operating at different security labels are deployed and controlled by a privileged management process that is also pre-configuring all information flows. This paper describes the design and objective of this layer.},
	booktitle = {SPIE Defense, Security, and Sensing},
	author = {Otte, William R. and Dubey, Abhishek and Karsai, Gabor},
	year = {2014}
}

@inproceedings{pan_dynamic_2010,
	title = {Dynamic Workflow Management and Monitoring Using DDS},
	doi = {10.1109/EASe.2010.12},
	abstract = {Large scientific computing data-centers require a distributed dependability subsystem that can provide fault isolation and recovery and is capable of learning and predicting failures to improve the reliability of scientific workflows. This paper extends our previous work on the autonomic scientific workflow management systems by presenting a hierarchical dynamic workflow management system that tracks the state of job execution using timed state machines. Workflow monitoring is achieved using a reliable distributed monitoring framework, which employs publish-subscribe middleware built upon OMG Data Distribution Service standard. Failure recovery is achieved by stopping and restarting the failed portions of workflow directed acyclic graph.},
	booktitle = {Engineering of Autonomic and Autonomous Systems (EASe), 2010 Seventh IEEE International Conference and Workshops on},
	author = {Pan, Pan and Dubey, Abhishek and Piccoli, Luciano},
	month = {mar},
	year = {2010},
	keywords = {Neural networks, middleware, Monitoring, Resource management, directed graphs, autonomic computing, autonomic scientific workflow management systems, computer centres, Computer network management, distributed dependability subsystem, distributed monitoring framework, failure recovery, fault isolation, hierarchical dynamic workflow management system, large scientific computing data centers, Maintenance, message passing, natural sciences computing, OMG data distribution service standard, Ontologies, Proposals, publish-subscribe middleware, Scalability, scientific workflow reliability, Software systems, Technology management, timed state machines, workflow directed acyclic graph, workflow management, workflow management software, workflow monitoring},
	pages = {20--29}
}

@inproceedings{pradhan_establishing_2014,
	title = {Establishing Secure Interactions across Distributed Applications in Satellite Clusters},
	doi = {10.1109/SMC-IT.2014.17},
	abstract = {Recent developments in small satellites have led to an increasing interest in building satellite clusters as open systems that provide a "cluster-as-a-service" in space. Since applications with different security classification levels must be supported in these open systems, the system must provide strict information partitioning such that only applications with matching security classifications interact with each other. The anonymous publish/subscribe communication pattern is a powerful interaction abstraction that has enjoyed great success in previous space software architectures, such as NASA's Core Flight Executive. However, the difficulty is that existing solutions that support anonymous publish/subscribe communication, such as the OMG Data Distribution Service (DDS), do not support information partitioning based on security classifications, which is a key requirement for some systems. This paper makes two contributions to address these limitations. First, we present a transport mechanism called Secure Transport that uses a lattice of labels to represent security classifications and enforces Multi-Level Security (MLS) policies to ensure strict information partitioning. Second, we present a novel discovery service that allows us to use an existing DDS implementation with our custom transport mechanism to realize a publish/subscribe middleware with information partitioning based on security classifications of applications. We also include an evaluation of our solution in the context of a use case scenario.},
	booktitle = {Space Mission Challenges for Information Technology (SMC-IT), 2014 IEEE International Conference on},
	author = {Pradhan, S. and Emfinger, W. and Dubey, A. and Otte, W.R. and Balasubramanian, D. and Gokhale, A. and Karsai, G. and Coglio, A.},
	month = {sep},
	year = {2014},
	keywords = {pattern classification, middleware, Middleware, software architecture, aerospace computing, distributed applications, artificial satellites, Security, publish-subscribe middleware, anonymous publish-subscribe communication pattern, cluster-as-a-service, Computer architecture, DDS, discovery service, information partitioning, interaction abstraction, MLS, Multi-Level Security, multilevel security policy, NASA core flight executive, OMG data distribution service, OMG Data Distribution Service, open systems, Peer-to-peer computing, satellite clusters, Satellites, Secure Discovery, secure interactions, Secure Publish/Subscribe Middleware, secure transport mechanism, security classification levels, security of data, Servers, space software architectures, Standards},
	pages = {67--74}
}

@inproceedings{pradhan_key_2014,
	address = {Laurel, MD, USE},
	title = {Key Considerations for a Resilient and Autonomous Deployment and Configuration Infrastructure for Cyber-Physical Systems},
	url = {http://www.isis.vanderbilt.edu/sites/default/files/Pradhan_EASe-2014.pdf},
	abstract = {Multi-module Cyber-Physical Systems (CPSs), such as satellite clusters, swarms of Unmanned Aerial Vehicles (UAV), and fleets of Unmanned Underwater Vehicles (UUV) are examples of managed distributed real-time systems where mission-critical applications, such as sensor fusion or coordinated flight control, are hosted. These systems are dynamic and reconfigurable, and provide a “CPS cluster-as-a-service” for mission-specific scientific applications that can benefit from the elasticity of the cluster membership and heterogeneity of the cluster members. The distributed and remote nature of these systems often necessitates the use of Deployment and Con- figuration (D\&C) services to manage the lifecycle of software applications. Fluctuating resources, volatile cluster membership and changing environmental conditions require resilient D\&C services. However, the dynamic nature of the system often precludes human intervention during the D\&C activities, which motivates the need for a self-adaptive D\&C infrastructure that supports autonomous resilience. Such an infrastructure must have the ability to adapt existing applications on-the-fly in order to provide application resilience and must itself be able to adapt to account for changes in the system as well as tolerate failures. This paper makes two contributions towards addressing these needed. First, we identify the key challenges in achieving such a self-adaptive D\&C infrastructure. Second, we present our ideas on resolving these challenges and realizing a self-adaptive D\&C infrastructure.},
	booktitle = {11th IEEE International Conference and Workshops on the Engineering of Autonomic and Autonomous Systems (EASe-2014)},
	publisher = {IEEE},
	author = {Pradhan, Subhav and Otte, William and Dubey, Abhishek and Gokhale, Aniruddha and Karsai, Gabor},
	year = {2014}
}

@inproceedings{saxena_enabling_2010,
	address = {Los Alamitos, CA, USA},
	title = {Enabling Self-Management by Using Model-Based Design Space Exploration},
	isbn = {978-0-7695-4004-7},
	doi = {http://doi.ieeecomputersociety.org/10.1109/EASe.2010.22},
	abstract = {Reconfiguration and self-management are important properties for systems that operate in hazardous and uncontrolled environments, such as inter-planetary space. These systems need a reconfiguration mechanism that provides recovery from individual component failures as well as the ability to dynamically adapt to evolving mission goals. One way to provide this functionality is to define a model of alternative system configurations and allow the system to choose the current configuration based on its current state, including environmental parameters and goals. The primary difficulties with this approach are (1) the state space of configurations can grow very large, which can make explicit enumeration infeasible, and (2) the component failures and evolving system goals must be somehow encoded in the system configuration model. This paper describes an online reconfiguration method based on model-based design-space exploration. We symbolically encode the set of valid system configurations and assert the current system state and goals as symbolic constraints. Our initial work indicates that this method scales and is capable of providing effective online dynamic reconfiguration.},
	booktitle = {7th IEEE International Workshop on Engineering of Autonomic \& Autonomous Systems (EASe)},
	publisher = {IEEE Computer Society},
	author = {Saxena, Tripti and Dubey, Abhishek and Balasubramanian, Daniel and Karsai, Gabor},
	year = {2010},
	pages = {137--144}
}

@inproceedings{mukhopadhyay_prioritized_2017,
	title = {Prioritized Allocation of Emergency Responders based on a Continuous-Time Incident Prediction Model},
	booktitle = {Autonomous Agents and Multiagent Systems (AAMAS)},
	author = {Mukhopadhyay, Ayan and Vorobeychik, Yevgeniy and Dubey, Abhishek and Biswas, Gautam},
	year = {2017}
}

@inproceedings{ghafouri_optimal_2017,
	title = {Optimal Detection of Faulty Traffic Sensors Used in Route Planning},
	booktitle = {AISOC},
	author = {Ghafouri, Amin and Laszka, Aron and Dubey, Abhishek and Koutsoukos, Xenofon},
	year = {2017},
	annote = {To Appear}
}

@article{laszka_providing_2017,
	title = {Providing Privacy, Safety, and Security in IoT-Based Transactive Energy Systems using Distributed Ledgers},
	journal = {IoT},
	author = {Laszka, A. and Dubey, A. and Walker, M. and Schmidt, D.},
	month = {sep},
	year = {2017},
	keywords = {and Cluster Computing, Computer Science - Distributed, Parallel, Computer Science - Cryptography and Security}
}

@inproceedings{hasan_heuristics-based_2017,
	title = {Heuristics-Based Approach for Identifying Critical N - k Contingencies in Power Systems},
	abstract = {Reliable operation of electrical power systems in the presence of multiple critical N - k contingencies is an important challenge for the system operators. Identifying all the possible N - k critical contingencies to design effective mitigation strategies is computationally infeasible due to the combinatorial explosion of the search space. This paper describes two heuristic algorithms based on the iterative pruning of the candidate contingency set to effectively and efficiently identify all the critical N - k contingencies resulting in system failure. These algorithms are applied to the standard IEEE-14 bus system, IEEE-39 bus system, and IEEE-57 bus system to identify multiple critical N-k contingencies. The algorithms are able to capture all the possible critical N - k contingencies (where 1 {\textless} k {\textless} 9) without missing any dangerous contingency.},
	booktitle = {Resilience Week},
	author = {Hasan, Saqib and Ghafouri, Amin and Dubey, Abhishek and Karsai, Gabor and Koutsoukos, Xenofon D.},
	month = {jul},
	year = {2017}
}

@inproceedings{du_implementation_2017,
	address = {Morgantown, WV},
	title = {Implementation of a Distributed Microgrid Controller on the Resilient Information Architecture Platform for Smart Systems (RIAPS)},
	abstract = {Formation of microgrids have been proposed as a solution to improve grid reliability, and enable smoother integration of renewables into the grid. Microgrids are sections of the grid that can operate in isolation from the main power system. Maintaining power balance within an islanded microgrid is a challenging task, due to the low system inertia, which requires complex control to maintain stable and optimized operation. Many studies have demonstrates feasible distributed microgrid controllers that can maintain microgrid stability in grid connected and islanded modes. However, there is little emphasis on how to implement these distributed algorithms on a computational platform that allows for fast and seamless deployment. This paper introduces a decentralized software platform called Resilient Information Architecture Platform for Smart Systems (RIAPS) that runs on processors embedded with the microgrid component. As an example, we describe the implementation of a distributed microgrid secondary control and resynchronization algorithms on RIAPS platform. The controller developed on RIAPS platform is validated on a real-time microgrid testbed.},
	booktitle = {2017 North American Power Symposium (NAPS)},
	publisher = {IEEE},
	author = {Du, Yuhua and Tu, Hao and Lukic, Srdjan and Lubkeman, David and Dubey, Abhishek and Karsai, Gabor},
	month = {sep},
	year = {2017}
}

@inproceedings{volgyesi_time_2017,
	title = {Time Synchronization Services for Low-cost Fog Computing Applications},
	abstract = {This paper presents the time synchronization infrastructure for a low-cost run-time platform and application framework specifically targeting Smart Grid applications. Such distributed applications require the execution of reliable and accurate time-coordinated actions and observations both within islands of deployments and across geographically distant nodes. The time synchronization infrastructure is built on well-established technologies: GPS, NTP, PTP, PPS and Linux with real-time extensions, running on low-cost BeagleBone Black hardware nodes. We describe the architecture, implementation, instrumentation approach, performance results and present an example from the application domain. Also, we discuss an important finding on the effect of the Linux {\textbackslash}textttRT\_PREEMPT real-time patch on the accuracy of the PPS subsystem and its use for GPS-based time reference},
	booktitle = {Rapid Systems Prototyping (RSP)},
	publisher = {IEEE},
	author = {Volgyesi, Peter and Dubey, Abhishek and Krentz, Timothy and Madari, Istvan and Metelko, Mary and Karsai, Gabor},
	month = {oct},
	year = {2017}
}

@inproceedings{barbour_data-driven_2018,
	title = {On the Data-Driven Prediction of Arrival Times for Freight Trains on U.S. Railroads},
	abstract = {The high capacity utilization and the pre- dominantly
      single-track network topology of freight rail- roads in the
      United States causes large variability and unpredictability
      of train arrival times. Predicting accurate estimated times
      of arrival (ETAs) is an important step for railroads to
      increase efficiency and automation, reduce costs, and
      enhance customer service. We propose using machine learning
      algorithms trained on historical railroad operational data
      to generate ETAs in real time. The machine learning
      framework is able to utilize the many data points produced
      by individual trains traversing a network track segment and
      generate periodic ETA pre- dictions with a single model. In
      this work we compare the predictive performance of linear
      and non-linear support vector regression, random forest
      regression, and deep neural network models, tested on a
      section of the railroad in Tennessee, USA using over two
      years of historical data. Support vector regression and
      deep neural network models show similar results with
      maximum ETA error reduction of 26\% over a statistical
      baseline predictor. The random forest models show over 60\%
      error reduction compared to baseline at some points and
      average error reduction of 42\%.},
	booktitle = {The 21st IEEE International Conference on Intelligent Transportation Systems},
	publisher = {IEEE},
	author = {Barbour, William and Samal, Chinamaya and Kuppa, Shankara and Dubey, Abhishek and Work, Daniel},
	month = {nov},
	year = {2018}
}
